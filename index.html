<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Fine-Grained Neural Network Explanation by Identifying Input Features with Predictive Information.">
  <meta name="keywords" content="Explanation, Interpretability, InputIBA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Fine-Grained Neural Network Explanation by Identifying Input Features with Predictive Information</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--  <div class="navbar-brand">-->
<!--    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--    </a>-->
<!--  </div>-->
<!--  <div class="navbar-menu">-->
<!--    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">-->
<!--      <a class="navbar-item" href="https://keunhong.com">-->
<!--      <span class="icon">-->
<!--          <i class="fas fa-home"></i>-->
<!--      </span>-->
<!--      </a>-->

<!--      <div class="navbar-item has-dropdown is-hoverable">-->
<!--        <a class="navbar-link">-->
<!--          More Research-->
<!--        </a>-->
<!--        <div class="navbar-dropdown">-->
<!--          <a class="navbar-item" href="https://hypernerf.github.io">-->
<!--            HyperNeRF-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://nerfies.github.io">-->
<!--            Nerfies-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://latentfusion.github.io">-->
<!--            LatentFusion-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://photoshape.github.io">-->
<!--            PhotoShape-->
<!--          </a>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->

<!--  </div>-->
<!--</nav>-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Fine-Grained Neural Network Explanation by Identifying Input Features with Predictive Information</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/yang-zhang-ml/">Yang Zhang *</a><sup>1</sup>, </span>
            <span class="author-block">
              <a href="www.linkedin.com/in/ashkankhakzar">Ashkan Khakzar *</a><sup>1</sup>, </span>
            <span class="author-block">
              <a href="http://www.linkedin.com/in/yawei-li-11013b203">Yawei Li</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="http://campar.in.tum.de/Main/AzadeFarshad">Azade Farshad</a><sup>1</sup>, 
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/sseongtaekim/">Seong Tae Kim</a><sup>3</sup>, 
            </span>
            <span class="author-block">
              <a href="http://campar.in.tum.de/Main/NassirNavabCv">Nassir Navab</a><sup>1,2</sup>, 
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Technical University of Munich,  </span>
            <span class="author-block"><sup>2</sup>Johns Hopkins University,  </span>
            <span class="author-block"><sup>3</sup>Kyung Hee University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Openreview Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=HglgPZAYhcG"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-comments"></i>
                  </span>
                  <span>OpenReview</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2110.01471"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/CAMP-eXplain-AI/InputIBA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
          <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/Z2oU11HMzds?rel=0&amp;showinfo=0"
                  frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
      <h2 class="subtitle has-text-centered">
        InputIBA generates saliency maps with input level resolution for CNNs and RNNs.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel-face" class="carousel results-carousel">
        <div class="item item-sketch-hq">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00003283_page-0001.jpg"
                   alt="XXX."/>
            <h2 class="subtitle has-text-centered">Explanation of "hoopskirt"</h2>
          </div>
        </div>
        <div class="item item-modegliani">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00017353_page-0001.jpg"
                   alt="Modegliani."/>
            <h2 class="subtitle has-text-centered">Explanation of "squirrel monkey"</h2>
          </div>
        </div>
        <div class="item item-mona-lisa">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00027234_page-0001.jpg"
                   alt="Mona Lisa."/>
            <h2 class="subtitle has-text-centered">Explanation of "pencil sharpener"</h2>
          </div>
        </div>
        <div class="item item-pixar">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00030411_page-0001.jpg"
                   alt="Pixar."/>
            <h2 class="subtitle has-text-centered">Explanation of "airliner"</h2>
          </div>
        </div>
        <div class="item item-ukiyo-e">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00035309_page-0001.jpg"
                   alt="Ukiyo-e."/>
            <h2 class="subtitle has-text-centered">Explanation of "sports car"</h2>
          </div>
        </div>
        <div class="item item-werewolf">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00039865_page-0001.jpg"
                   alt="Werewolf."/>
            <h2 class="subtitle has-text-centered">Explanation of "great white shark"</h2>
          </div>
        </div>
        <div class="item item-zombie">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00046423_page-0001.jpg"
                   alt="Zombie."/>
            <h2 class="subtitle has-text-centered">Explanation of "husky"</h2>
          </div>
        </div>
        <div class="item item-neanderthal">
          <div class="carousel-content">
            <img src="static/images/ffhq/ILSVRC2012_val_00049815_page-0001.jpg"
                   alt="Neanderthal."/>
            <h2 class="subtitle has-text-centered">Explanation of "groenendael"</h2>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section Abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            One principal approach for illuminating a black-box neural network is feature attribution, i.e. identifying the importance of input features for the network’s prediction. 
            The predictive information of features is recently proposed as a proxy for the measure of their importance. 
          </p>
          <p>
            So far, the predictive information is only identified for latent features by placing an information bottleneck within the network. We propose a method to identify features with 
            predictive information in the input domain.
          </p>
          <p>
            The method results in fine-grained identification of input features’ information and 
            is agnostic to network architecture. The core idea of our method is leveraging a 
            bottleneck on the input that only lets input features associated with predictive latent 
            features pass through. 
          </p>
          <p>
            We compare our method with several feature attribution 
            methods using mainstream feature attribution evaluation experiments. The code is publicly available.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <!--/ Architecture. -->
        
        <div class="section-title">
          <h2 class="title is-3 is-centered">How does it work?</h2>
        </div>
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div class="publication-img">
              <img id="architecture" src="static/images/paper_figs/show_problem.jpg"/>
            </div>
          </div>
        </div>
        <div class="content has-text-justified">
		<p>Previously, information-theory-based attribution inserts a information bottleneck in the <b>latent feature</b>. 
		We see the result of applying information bottleneck on different layers of a VGG16 network (from conv4_1 to conv1_1). 
		</p>
		<p>
		The approximations (averaging across channels) in IBA result in the assignment of information to irrelevant areas of the 
		image (the trashcan and areas around the image). Upscale using interpolation also causes the attribution map to be blurry and inaccurate.
		</p>
		<p>
		As we move towards earlier layers (conv1_1), the information is distributed equally between features, and less information is assigned to the most
		relevant feature (the broom), due to the <b>overestimation of mutual information</b> in IBA.
		</p>
		<p>
		InputIBA aims to come up with a more reasonable choice for approximation of bottleneck variable such that it is applicable for the input. 
		In addition, InputIBA computes the mutual information directly in the input space and avoid the approximation issues inherent in IBA.
		</p>
		<p>
		We take advantage of the gaussian distribution approximation of bottleneck being reasonable for deep layers. 
		Thus, we first find a bottleneck variable, \(Z^*\), that corresponds to predictive deep features, by solving the IBA optimization problem on a hidden layer. 
		The bottleneck \(Z^*\) restricts the flow of information through the network and keeps deep features with predictive information. 
		</p>
		<p>
		Then, InputIBA use a Wasserstein-GAN to fit a bottleneck variable \(Z_G\) ”on the input”, that corresponds to deep botthleneck \(Z^*\). 
		This translates to finding a mask on input features that admits input features which correspond to informative deep features. 
		</p>
		<p>
		The final goal is keeping only predictive features of input, therefore, the input bottleneck \(Z_G\) can be used as prior knowledge for the distribution of input bottleneck \(Z_I\).
		We then proceed and solve the optimization by using \(Z_G\) as a prior for \(Z_I\). We refer to this methodology as InputIBA.
		</p>
	</div>
      <div class="container is-max-desktop">
        <!-- Training video. -->
        
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="publication-video-small">
              <video id="training_vid" autoplay controls muted height="100%">
               <source src="static/videos/method.mp4"
                       type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered">Overview of InputIBA</h2>
            </div>
          </div>
        </div>
        <!--/ Training video. -->
      </div>
      
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

      <div class="section-title">
        <h2 class="title is-3">Model-Agnostic Attribution</h2>
      </div>

    <div class="columns is-centered">

      <!-- Cross domain. -->
      
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p>
              InputIBA can generate attribution for different model architectures across domains, thus a general framework for explaining neural network models.
            </p>
            <div class="publication-img">
              <img id="pitt_editing" src="static/images/paper_figs/vision_result.jpg"/>
            </div>
          </div>
        </div>
      </div>
      <!--/ Cross domain. -->

      <!-- New domain editing. -->
      
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We applied InputIBA on a sentimental classification task learned on IMDB dataset. The model is a multi-layer LSTM, a recurrent neural network.
            </p>
            <div class="publication-img">
              <img id="pitt_editing" src="static/images/paper_figs/NLP_result.PNG"/>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ New domain editing. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>If you find our work useful, please cite our paper:</p>
    <pre><code>@inproceedings{
	zhang2021finegrained,
	title={Fine-Grained Neural Network Explanation by Identifying Input Features with Predictive Information},
	author={Yang Zhang and Ashkan Khakzar and Yawei Li and Azade Farshad and Seong Tae Kim and Nassir Navab},
	booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
	year={2021},
	url={https://openreview.net/forum?id=HglgPZAYhcG}
}
</code></pre>
  </div>
</section>
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2110.01471">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/CAMP-eXplain-AI/InputIBA" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on both the <a href="https://stylegan-nada.github.io"> StyleGAN-NADA</a> project page and the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
